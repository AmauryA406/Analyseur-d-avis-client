"""
Analyseur d'Avis Clients avec Groq LLM - Version Production
===========================================================

Analyse RÃ‰ELLE de vos 317 avis Amazon avec Groq Llama-3.1 (GRATUIT).
"""

import json
import pandas as pd
import time
import os
from pathlib import Path
from typing import List, Dict
from collections import Counter

try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    print("âŒ Module 'groq' non installÃ©. Installez avec: pip install groq")

class GroqAnalyzer:
    """Analyseur utilisant Groq Llama-3.1 pour analyse rÃ©elle."""
    
    def __init__(self, api_key: str = None):
        """Initialise l'analyseur Groq."""
        
        if not GROQ_AVAILABLE:
            raise ImportError("Module groq requis: pip install groq")
        
        # RÃ©cupÃ©rer clÃ© API
        self.api_key = api_key or os.getenv('GROQ_API_KEY')
        
        if not self.api_key:
            raise ValueError(
                "ğŸ”‘ ClÃ© API Groq requise!\n"
                "ğŸ’¡ Obtenez une clÃ© gratuite: https://console.groq.com/keys\n"
                "ğŸ”§ Puis: export GROQ_API_KEY=your_key"
            )
        
        # Initialiser client Groq
        self.client = Groq(api_key=self.api_key)
        
        # Statistiques
        self.stats = {
            'api_calls': 0,
            'tokens_used': 0,
            'total_cost': 0.0,  # Groq est gratuit!
            'avg_response_time': 0.0
        }
        
        # Topics dÃ©couverts (seront remplis par Phase 1)
        self.discovered_topics = []
        self.topic_descriptions = {}
        
        print("âœ… Groq Analyzer initialisÃ© avec Llama-3.1!")
        print(f"ğŸ†“ Limite quotidienne: 14,400 requÃªtes (largement suffisant)")
    
    def discover_topics_with_groq(self, reviews_sample: List[str]) -> Dict:
        """Phase 1: DÃ©couverte automatique des topics via Groq."""
        
        print(f"ğŸ” PHASE 1: DÃ©couverte de topics avec Groq sur {len(reviews_sample)} avis")
        
        # PrÃ©parer Ã©chantillon pour prompt (limiter Ã  ~20 avis pour taille prompt)
        sample_text = "\n".join([
            f"Avis {i+1}: {review[:200]}" for i, review in enumerate(reviews_sample[:20])
        ])
        
        prompt = f"""Tu es un expert en analyse de donnÃ©es clients. Analyse ces avis sur une montre connectÃ©e et identifie les THÃˆMES RÃ‰CURRENTS mentionnÃ©s.

IMPORTANT: Base-toi UNIQUEMENT sur ce qui est rÃ©ellement dit dans les avis. Ne prÃ©suppose rien.

AVIS CLIENTS:
{sample_text}

Concentre-toi sur:
- Quels aspects du produit reviennent souvent?
- Quels problÃ¨mes sont frÃ©quemment mentionnÃ©s?
- Quelles fonctionnalitÃ©s sont discutÃ©es?
- Quels points positifs ressortent?

RÃ©ponds UNIQUEMENT avec ce JSON (pas de texte avant/aprÃ¨s):
{{
    "discovered_topics": ["theme1", "theme2", "theme3", "theme4", "theme5"],
    "topic_descriptions": {{
        "theme1": "Description courte de ce thÃ¨me",
        "theme2": "Description courte de ce thÃ¨me"
    }},
    "confidence": 0.85
}}

JSON:"""

        try:
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,  # Peu de crÃ©ativitÃ© pour consistance
                max_tokens=800
            )
            
            response_time = time.time() - start_time
            result_text = response.choices[0].message.content.strip()
            
            # Mettre Ã  jour stats
            self.stats['api_calls'] += 1
            self.stats['avg_response_time'] = response_time
            
            print(f"âš¡ RÃ©ponse Groq reÃ§ue en {response_time:.2f}s")
            
            # Parser le JSON
            try:
                result = json.loads(result_text)
                
                self.discovered_topics = result.get('discovered_topics', [])
                self.topic_descriptions = result.get('topic_descriptions', {})
                
                print(f"ğŸ¯ {len(self.discovered_topics)} topics dÃ©couverts par Groq!")
                
                return result
                
            except json.JSONDecodeError:
                print(f"âš ï¸ RÃ©ponse Groq non-JSON:")
                print(f"'{result_text[:200]}...'")
                # Fallback: extraction manuelle si possible
                return self._extract_topics_fallback(result_text)
        
        except Exception as e:
            print(f"âŒ Erreur appel Groq: {e}")
            return {"discovered_topics": [], "topic_descriptions": {}, "error": str(e)}
    
    def _extract_topics_fallback(self, text: str) -> Dict:
        """Extraction manuelle si JSON parsing Ã©choue."""
        print("ğŸ”§ Tentative extraction manuelle...")
        
        # Recherche patterns basiques
        topics = []
        if "discovered_topics" in text:
            # Extraire entre crochets
            import re
            topic_match = re.search(r'"discovered_topics":\s*\[(.*?)\]', text, re.DOTALL)
            if topic_match:
                topic_text = topic_match.group(1)
                topics = re.findall(r'"([^"]+)"', topic_text)
        
        return {
            "discovered_topics": topics[:8],  # Max 8 topics
            "topic_descriptions": {topic: f"Topic extrait: {topic}" for topic in topics[:8]},
            "confidence": 0.5,
            "extraction_method": "fallback"
        }
    
    def analyze_review_with_groq(self, review_text: str, discovered_topics: List[str]) -> Dict:
        """Phase 2: Analyse d'un avis avec les topics dÃ©couverts."""
        
        if not discovered_topics:
            discovered_topics = ["general"]
        
        topics_str = ", ".join(discovered_topics)
        
        prompt = f"""Tu es un expert en analyse de sentiment. Analyse cet avis client sur une montre connectÃ©e.

TOPICS IDENTIFIÃ‰S COMME IMPORTANTS: {topics_str}

AVIS Ã€ ANALYSER: "{review_text}"

Analyse le sentiment global ET le sentiment pour chaque topic mentionnÃ©.

RÃ©ponds UNIQUEMENT avec ce JSON (pas de texte avant/aprÃ¨s):
{{
    "sentiment_global": "positif|neutre|nÃ©gatif",
    "score_sentiment": 0.75,
    "confiance": 0.85,
    "topics_mentionnÃ©s": ["topic1", "topic2"],
    "sentiment_par_topic": {{
        "topic1": "positif|neutre|nÃ©gatif",
        "topic2": "positif|neutre|nÃ©gatif"
    }},
    "points_clÃ©s": ["Point principal 1", "Point principal 2"],
    "recommandation": "Action recommandÃ©e pour l'entreprise"
}}

JSON:"""

        try:
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=600
            )
            
            response_time = time.time() - start_time
            result_text = response.choices[0].message.content.strip()
            
            # Stats
            self.stats['api_calls'] += 1
            self.stats['avg_response_time'] = (
                (self.stats['avg_response_time'] * (self.stats['api_calls'] - 1) + response_time) 
                / self.stats['api_calls']
            )
            
            # Parser JSON
            try:
                return json.loads(result_text)
            except json.JSONDecodeError:
                print(f"âš ï¸ JSON parsing failed pour avis, rÃ©ponse: '{result_text[:100]}...'")
                return {
                    "sentiment_global": "neutre",
                    "score_sentiment": 0.5,
                    "confiance": 0.3,
                    "topics_mentionnÃ©s": [],
                    "sentiment_par_topic": {},
                    "points_clÃ©s": ["Erreur parsing JSON"],
                    "recommandation": "Revoir le prompt Groq",
                    "raw_response": result_text[:200]
                }
        
        except Exception as e:
            print(f"âŒ Erreur analyse avis: {e}")
            return {
                "sentiment_global": "erreur",
                "score_sentiment": 0.0,
                "confiance": 0.0,
                "topics_mentionnÃ©s": [],
                "sentiment_par_topic": {},
                "points_clÃ©s": [f"Erreur: {e}"],
                "recommandation": "VÃ©rifier connexion Groq",
                "error": str(e)
            }

def load_amazon_data():
    """Charge vos donnÃ©es Amazon nettoyÃ©es."""
    possible_paths = [
        "V1.0/data/processed/avis_amazon_clean_complete.json",
        "../data/processed/avis_amazon_clean_complete.json",
        "avis_amazon_clean_complete.json"
    ]
    
    for path in possible_paths:
        if Path(path).exists():
            print(f"ğŸ“Š Chargement: {path}")
            df = pd.read_json(path)
            print(f"âœ… {len(df)} avis chargÃ©s")
            
            # Distribution par note
            note_dist = df['note'].value_counts().sort_index()
            for note, count in note_dist.items():
                print(f"   {note}â­: {count} avis ({count/len(df)*100:.1f}%)")
            
            return df
    
    print("âŒ Dataset non trouvÃ©")
    return None

def run_complete_groq_analysis():
    """Pipeline complet avec Groq."""
    
    print("ğŸš€ ANALYSE COMPLÃˆTE AVEC GROQ LLM")
    print("=" * 60)
    
    # VÃ©rifier clÃ© API
    if not os.getenv('GROQ_API_KEY'):
        print("ğŸ”‘ Configuration clÃ© Groq:")
        api_key = input("Entrez votre clÃ© API Groq (ou ENTER si dÃ©finie dans env): ").strip()
        if api_key:
            os.environ['GROQ_API_KEY'] = api_key
        else:
            print("âŒ ClÃ© API requise. Obtenez-la sur: https://console.groq.com/keys")
            return
    
    # Charger donnÃ©es
    df = load_amazon_data()
    if df is None:
        return
    
    # PrÃ©parer donnÃ©es
    text_col = 'texte_clean' if 'texte_clean' in df.columns else 'texte'
    df_clean = df[df[text_col].notna()]
    df_clean = df_clean[df_clean[text_col].str.len() > 10]
    
    print(f"ğŸ“ {len(df_clean)} avis analysables")
    
    # Initialiser Groq
    try:
        analyzer = GroqAnalyzer()
    except Exception as e:
        print(f"âŒ Erreur init Groq: {e}")
        return
    
    # PHASE 1: DÃ©couverte topics
    print(f"\nğŸ” PHASE 1: DÃ©couverte topics avec Groq")
    
    # Ã‰chantillon stratifiÃ© (10 avis par note)
    discovery_sample = []
    for note in sorted(df_clean['note'].unique()):
        note_reviews = df_clean[df_clean['note'] == note][text_col].tolist()
        discovery_sample.extend(note_reviews[:10])  # 10 par note max
    
    print(f"ğŸ“Š Ã‰chantillon: {len(discovery_sample)} avis")
    
    # DÃ©couverte avec Groq
    discovery_result = analyzer.discover_topics_with_groq(discovery_sample)
    
    if not discovery_result.get('discovered_topics'):
        print("âŒ Aucun topic dÃ©couvert, arrÃªt")
        return
    
    print(f"\nğŸ¯ TOPICS DÃ‰COUVERTS PAR GROQ:")
    for i, topic in enumerate(discovery_result['discovered_topics'], 1):
        desc = discovery_result['topic_descriptions'].get(topic, 'Pas de description')
        print(f"   {i}. {topic}")
        print(f"      ğŸ“ {desc}")
    
    # PHASE 2: Analyse avec topics dÃ©couverts
    print(f"\nğŸ¤– PHASE 2: Analyse avec Groq sur Ã©chantillon")
    
    # Analyser 30 avis pour commencer (Ã©conomiser quota API)
    sample_size = 30
    print(f"ğŸ“Š Analyse de {sample_size} avis (pour Ã©conomiser quota API)...")
    
    analysis_results = []
    df_sample = df_clean.head(sample_size)
    
    for idx, row in df_sample.iterrows():
        print(f"   ğŸ”„ Analyse avis {len(analysis_results)+1}/{sample_size}...", end=' ')
        
        try:
            review_text = str(row[text_col])
            result = analyzer.analyze_review_with_groq(
                review_text, 
                discovery_result['discovered_topics']
            )
            
            # Combiner donnÃ©es originales + analyse
            full_result = {
                'id': row.get('id', idx),
                'note_originale': row['note'],
                'auteur': row.get('auteur', 'Anonyme'),
                'avis_texte': review_text[:150] + "..." if len(review_text) > 150 else review_text,
                **result  # Ajouter tous les rÃ©sultats Groq
            }
            
            analysis_results.append(full_result)
            print(f"âœ… {result.get('sentiment_global', 'N/A')}")
            
            # Pause courte pour Ã©viter rate limiting
            time.sleep(0.2)
            
        except Exception as e:
            print(f"âŒ Erreur: {e}")
            continue
    
    print(f"\nğŸ“Š ANALYSE TERMINÃ‰E: {len(analysis_results)} avis analysÃ©s")
    print(f"âš¡ Stats Groq: {analyzer.stats['api_calls']} appels API, "
          f"{analyzer.stats['avg_response_time']:.2f}s moyenne")
    
    # RÃ‰SULTATS ET INSIGHTS
    print(f"\nğŸ“ˆ RÃ‰SULTATS GROQ:")
    
    # Distribution sentiment
    sentiments = [r.get('sentiment_global', 'inconnu') for r in analysis_results]
    sentiment_counts = Counter(sentiments)
    
    print(f"\nğŸ˜Š SENTIMENTS DÃ‰TECTÃ‰S PAR GROQ:")
    for sentiment, count in sentiment_counts.items():
        pct = (count / len(analysis_results)) * 100
        emoji = "ğŸ˜Š" if sentiment == "positif" else "ğŸ˜" if sentiment == "neutre" else "ğŸ˜"
        print(f"   {emoji} {sentiment.upper()}: {count} avis ({pct:.1f}%)")
    
    # Topics les plus mentionnÃ©s
    all_topics_mentioned = []
    for result in analysis_results:
        topics = result.get('topics_mentionnÃ©s', [])
        all_topics_mentioned.extend(topics)
    
    topic_mentions = Counter(all_topics_mentioned)
    
    if topic_mentions:
        print(f"\nğŸ”¥ TOPICS LES PLUS DISCUTÃ‰S (selon Groq):")
        for topic, count in topic_mentions.most_common(8):
            pct = (count / len(analysis_results)) * 100
            print(f"   ğŸ“Œ {topic}: {count} mentions ({pct:.1f}%)")
    
    # Recommandations Groq
    all_recommendations = [r.get('recommandation', '') for r in analysis_results if r.get('recommandation')]
    
    print(f"\nğŸ’¡ RECOMMANDATIONS GROQ (Ã©chantillon):")
    unique_recommendations = list(set(all_recommendations))[:5]
    for i, rec in enumerate(unique_recommendations, 1):
        if rec and len(rec) > 10:
            print(f"   {i}. {rec}")
    
    # CohÃ©rence avec notes Ã©toiles
    print(f"\nâ­ COHÃ‰RENCE GROQ vs NOTES Ã‰TOILES:")
    coherence_check = {}
    
    for result in analysis_results:
        note = result.get('note_originale')
        sentiment = result.get('sentiment_global')
        
        if note not in coherence_check:
            coherence_check[note] = []
        coherence_check[note].append(sentiment)
    
    for note in sorted(coherence_check.keys()):
        sentiments_for_note = coherence_check[note]
        sentiment_dist = Counter(sentiments_for_note)
        print(f"   {note}â­ ({len(sentiments_for_note)} avis): {dict(sentiment_dist)}")
    
    # Exemples d'analyses
    print(f"\nğŸ“ EXEMPLES D'ANALYSES GROQ:")
    for i, result in enumerate(analysis_results[:3], 1):
        print(f"\n   Exemple {i}:")
        print(f"   ğŸ“„ Avis: \"{result.get('avis_texte', '')}\"")
        print(f"   â­ Note: {result.get('note_originale')}â­")
        print(f"   ğŸ¯ Groq Sentiment: {result.get('sentiment_global')} ({result.get('score_sentiment', 0):.2f})")
        print(f"   ğŸ“Œ Topics: {result.get('topics_mentionnÃ©s', [])}")
        print(f"   ğŸ’¡ Recommandation: {result.get('recommandation', 'N/A')}")
    
    # Sauvegarder rÃ©sultats
    output_file = "V1.0/data/processed/groq_analysis_results.json"
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'discovery_phase': discovery_result,
                'analysis_results': analysis_results,
                'summary': {
                    'total_analyzed': len(analysis_results),
                    'sentiment_distribution': dict(sentiment_counts),
                    'topic_mentions': dict(topic_mentions.most_common(10)),
                    'groq_stats': analyzer.stats
                }
            }, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ RÃ©sultats sauvÃ©s: {output_file}")
    except Exception as e:
        print(f"âš ï¸ Erreur sauvegarde: {e}")
    
    print(f"\nğŸ‰ ANALYSE GROQ TERMINÃ‰E!")
    print(f"ğŸ”¥ Vous avez maintenant une analyse LLM rÃ©elle de vos avis!")

if __name__ == "__main__":
    run_complete_groq_analysis()