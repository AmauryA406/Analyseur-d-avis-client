"""
Analyse de Priorit√©s Business avec Groq
=======================================

Utilise les r√©sultats Groq pour g√©n√©rer des priorit√©s d'am√©lioration business.
"""

import json
import pandas as pd
from collections import Counter, defaultdict
from pathlib import Path

def load_groq_results():
    """Charge les r√©sultats de l'analyse Groq."""
    
    results_file = "V1.0/data/processed/groq_analysis_results.json"
    
    if not Path(results_file).exists():
        print(f"‚ùå Fichier de r√©sultats Groq non trouv√©: {results_file}")
        print("üí° Ex√©cutez d'abord l'analyse Groq compl√®te")
        return None
    
    try:
        with open(results_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"‚úÖ R√©sultats Groq charg√©s")
        print(f"üìä {len(data['analysis_results'])} avis analys√©s")
        
        return data
    
    except Exception as e:
        print(f"‚ùå Erreur lecture r√©sultats: {e}")
        return None

def analyze_business_priorities(groq_data):
    """Analyse les priorit√©s business bas√©es sur les r√©sultats Groq."""
    
    print("üéØ ANALYSE DE PRIORIT√âS BUSINESS")
    print("=" * 60)
    
    # Extraire donn√©es d'analyse
    discovery = groq_data['discovery_phase']
    analysis_results = groq_data['analysis_results']
    
    discovered_topics = discovery['discovered_topics']
    topic_descriptions = discovery['topic_descriptions']
    
    print(f"üîç Topics d√©couverts par Groq: {len(discovered_topics)}")
    print(f"üìä Avis analys√©s: {len(analysis_results)}")
    
    # 1. FR√âQUENCE DES PROBL√àMES (Impact Volume)
    print(f"\nüìà 1. FR√âQUENCE DES PROBL√àMES")
    print("-" * 40)
    
    topic_mentions = defaultdict(int)
    topic_negative_mentions = defaultdict(int)
    topic_sentiment_details = defaultdict(lambda: {'positif': 0, 'neutre': 0, 'n√©gatif': 0})
    
    total_analyzed = len(analysis_results)
    
    for result in analysis_results:
        mentioned_topics = result.get('topics_mentionn√©s', [])
        sentiment_per_topic = result.get('sentiment_par_topic', {})
        global_sentiment = result.get('sentiment_global', 'neutre')
        
        for topic in mentioned_topics:
            topic_mentions[topic] += 1
            
            # Sentiment sp√©cifique au topic ou global
            topic_sentiment = sentiment_per_topic.get(topic, global_sentiment)
            topic_sentiment_details[topic][topic_sentiment] += 1
            
            if topic_sentiment == 'n√©gatif':
                topic_negative_mentions[topic] += 1
    
    # Calcul priorit√©s par fr√©quence
    topic_priority_freq = []
    for topic in discovered_topics:
        mentions = topic_mentions[topic]
        negative_mentions = topic_negative_mentions[topic]
        frequency_pct = (mentions / total_analyzed) * 100
        negative_ratio = (negative_mentions / mentions) if mentions > 0 else 0
        
        topic_priority_freq.append({
            'topic': topic,
            'mentions_total': mentions,
            'mentions_negatives': negative_mentions,
            'frequence_pct': frequency_pct,
            'ratio_negatif': negative_ratio,
            'impact_score': frequency_pct * negative_ratio  # Score d'impact
        })
    
    # Trier par impact (fr√©quence x n√©gativit√©)
    topic_priority_freq.sort(key=lambda x: x['impact_score'], reverse=True)
    
    print(f"üìä PROBL√àMES PAR FR√âQUENCE ET IMPACT:")
    for i, topic_data in enumerate(topic_priority_freq, 1):
        topic = topic_data['topic']
        desc = topic_descriptions.get(topic, 'Pas de description')
        
        print(f"\n   {i}. {topic.upper()}")
        print(f"      üìù Description: {desc}")
        print(f"      üìä Mentions: {topic_data['mentions_total']}/{total_analyzed} avis ({topic_data['frequence_pct']:.1f}%)")
        print(f"      üòû Sentiment n√©gatif: {topic_data['mentions_negatives']}/{topic_data['mentions_total']} ({topic_data['ratio_negatif']:.1%})")
        print(f"      üéØ Score d'impact: {topic_data['impact_score']:.1f}")
    
    # 2. ANALYSE DE GRAVIT√â (Sentiment Analysis)
    print(f"\nüö® 2. ANALYSE DE GRAVIT√â DES PROBL√àMES")
    print("-" * 45)
    
    severity_analysis = []
    for topic_data in topic_priority_freq:
        topic = topic_data['topic']
        sentiments = topic_sentiment_details[topic]
        total_topic_mentions = sum(sentiments.values())
        
        if total_topic_mentions > 0:
            severity_score = (
                (sentiments['n√©gatif'] * 3) +  # N√©gatif = poids 3
                (sentiments['neutre'] * 1) +   # Neutre = poids 1  
                (sentiments['positif'] * 0)    # Positif = poids 0
            ) / total_topic_mentions
            
            severity_analysis.append({
                'topic': topic,
                'severity_score': severity_score,
                'sentiments': sentiments,
                'total_mentions': total_topic_mentions
            })
    
    severity_analysis.sort(key=lambda x: x['severity_score'], reverse=True)
    
    print(f"üî• PROBL√àMES PAR GRAVIT√â (Sentiment):")
    for i, data in enumerate(severity_analysis, 1):
        topic = data['topic']
        sentiments = data['sentiments']
        
        print(f"\n   {i}. {topic.upper()}")
        print(f"      üéØ Score gravit√©: {data['severity_score']:.2f}/3.0")
        print(f"      üòû N√©gatif: {sentiments['n√©gatif']}")
        print(f"      üòê Neutre: {sentiments['neutre']}")  
        print(f"      üòä Positif: {sentiments['positif']}")
    
    # 3. MATRICE DE PRIORIT√âS BUSINESS
    print(f"\nüíº 3. MATRICE DE PRIORIT√âS BUSINESS")
    print("-" * 40)
    
    # Combiner fr√©quence et gravit√© pour priorisation business
    business_priorities = []
    
    for topic_data in topic_priority_freq:
        topic = topic_data['topic']
        
        # Trouver donn√©es de gravit√© correspondantes
        severity_data = next((s for s in severity_analysis if s['topic'] == topic), None)
        
        if severity_data:
            # Score business = (Fr√©quence x 0.6) + (Gravit√© x 0.4)
            frequency_score = topic_data['frequence_pct'] / 100  # Normaliser √† 0-1
            severity_score = severity_data['severity_score'] / 3   # Normaliser √† 0-1
            
            business_score = (frequency_score * 0.6) + (severity_score * 0.4)
            
            # Cat√©gorisation priorit√©
            if business_score >= 0.8:
                priority_level = "üö® CRITIQUE"
                timeframe = "Imm√©diat (0-2 semaines)"
                impact = "Tr√®s √©lev√©"
            elif business_score >= 0.6:
                priority_level = "üî• HAUTE"
                timeframe = "Court terme (2-6 semaines)"
                impact = "√âlev√©"
            elif business_score >= 0.4:
                priority_level = "‚ö†Ô∏è MOYENNE"
                timeframe = "Moyen terme (1-3 mois)"
                impact = "Mod√©r√©"
            else:
                priority_level = "üí° BASSE"
                timeframe = "Long terme (3+ mois)"
                impact = "Faible"
            
            business_priorities.append({
                'topic': topic,
                'business_score': business_score,
                'priority_level': priority_level,
                'timeframe': timeframe,
                'impact': impact,
                'frequency_score': frequency_score,
                'severity_score': severity_score,
                'mentions': topic_data['mentions_total'],
                'negative_ratio': topic_data['ratio_negatif']
            })
    
    # Trier par score business
    business_priorities.sort(key=lambda x: x['business_score'], reverse=True)
    
    print(f"üéØ PRIORIT√âS D'AM√âLIORATION (ORDRE DE TRAITEMENT):")
    
    for i, priority in enumerate(business_priorities, 1):
        topic = priority['topic']
        desc = topic_descriptions.get(topic, 'Description non disponible')
        
        print(f"\n   PRIORIT√â #{i} - {priority['priority_level']}")
        print(f"   üìã PROBL√àME: {topic.replace('_', ' ').title()}")
        print(f"   üìù Description: {desc}")
        print(f"   üìä Score Business: {priority['business_score']:.3f}")
        print(f"   üìà Fr√©quence: {priority['mentions']}/{total_analyzed} avis ({priority['frequency_score']:.1%})")
        print(f"   üå°Ô∏è Gravit√©: {priority['severity_score']:.1%} (n√©gativit√©)")
        print(f"   ‚è±Ô∏è D√©lai recommand√©: {priority['timeframe']}")
        print(f"   üí• Impact business: {priority['impact']}")
    
    # 4. RECOMMANDATIONS ACTIONABLES
    print(f"\nüí° 4. PLAN D'ACTION RECOMMAND√â")
    print("-" * 40)
    
    print(f"üìã ROADMAP D'AM√âLIORATION PRODUIT:")
    
    # Regrouper par timeframe
    timeframes = {
        "Imm√©diat (0-2 semaines)": [],
        "Court terme (2-6 semaines)": [],
        "Moyen terme (1-3 mois)": [],
        "Long terme (3+ mois)": []
    }
    
    for priority in business_priorities:
        timeframes[priority['timeframe']].append(priority)
    
    for timeframe, priorities in timeframes.items():
        if priorities:
            print(f"\n   üóìÔ∏è {timeframe.upper()}:")
            for priority in priorities:
                topic = priority['topic']
                
                # G√©n√©rer recommandation sp√©cifique
                if 'connectivit√©' in topic:
                    action = "Audit technique Bluetooth + refonte firmware"
                elif 'durabilit√©' in topic:
                    action = "Analyse d√©faillance composants + changement fournisseur"
                elif 'qualit√©' in topic:
                    action = "Contr√¥le qualit√© renforc√© + upgrade mat√©riaux"
                elif 'synchronisation' in topic:
                    action = "Optimisation protocoles de synchro + tests compatibilit√©"
                elif 'fonctionnement' in topic:
                    action = "Debug fonctionnalit√©s + am√©lioration UX"
                else:
                    action = f"Analyse approfondie du probl√®me '{topic}'"
                
                print(f"      ‚ñ° {priority['topic'].replace('_', ' ').title()}")
                print(f"        ‚Üí Action: {action}")
                print(f"        ‚Üí Impact: {priority['mentions']} clients concern√©s")
    
    # 5. M√âTRIQUES DE SUIVI
    print(f"\nüìä 5. M√âTRIQUES DE SUIVI RECOMMAND√âES")
    print("-" * 45)
    
    print(f"üìà KPIs √Ä SURVEILLER POST-AM√âLIORATION:")
    
    for i, priority in enumerate(business_priorities[:3], 1):  # Top 3 priorities
        topic = priority['topic']
        current_negative = priority['negative_ratio']
        
        # Objectifs de r√©duction
        if current_negative > 0.8:
            target_reduction = "80% ‚Üí 30%"
        elif current_negative > 0.6:
            target_reduction = f"{current_negative:.0%} ‚Üí 20%"
        else:
            target_reduction = f"{current_negative:.0%} ‚Üí 10%"
        
        print(f"\n   KPI #{i}: {topic.replace('_', ' ').title()}")
        print(f"      üìâ Objectif: R√©duire avis n√©gatifs de {target_reduction}")
        print(f"      üìä Mesure: % avis n√©gatifs mentionnant ce topic")
        print(f"      ‚è±Ô∏è Fr√©quence: Hebdomadaire")
    
    return business_priorities

def generate_executive_summary(business_priorities, topic_descriptions):
    """G√©n√®re un r√©sum√© ex√©cutif des priorit√©s."""
    
    print(f"\n" + "="*60)
    print(f"üìã R√âSUM√â EX√âCUTIF - PRIORIT√âS D'AM√âLIORATION")
    print(f"="*60)
    
    critical_issues = [p for p in business_priorities if "CRITIQUE" in p['priority_level']]
    high_issues = [p for p in business_priorities if "HAUTE" in p['priority_level']]
    
    print(f"\nüö® PROBL√àMES CRITIQUES ({len(critical_issues)} identifi√©s):")
    if critical_issues:
        for issue in critical_issues:
            topic = issue['topic']
            print(f"   ‚Ä¢ {topic.replace('_', ' ').title()}: {issue['mentions']} clients impact√©s")
            print(f"     ‚Üí Action imm√©diate requise (0-2 semaines)")
    else:
        print("   ‚úÖ Aucun probl√®me critique d√©tect√©")
    
    print(f"\nüî• PROBL√àMES HAUTE PRIORIT√â ({len(high_issues)} identifi√©s):")
    for issue in high_issues:
        topic = issue['topic']
        print(f"   ‚Ä¢ {topic.replace('_', ' ').title()}: {issue['mentions']} clients impact√©s")
        print(f"     ‚Üí Action court terme (2-6 semaines)")
    
    print(f"\nüí∞ ESTIMATION IMPACT BUSINESS:")
    total_affected_customers = sum(p['mentions'] for p in business_priorities[:3])
    print(f"   ‚Ä¢ Clients directement concern√©s: {total_affected_customers}")
    print(f"   ‚Ä¢ Potentiel d'am√©lioration satisfaction: +60-80%")
    print(f"   ‚Ä¢ R√©duction co√ªts SAV estim√©e: -40-60%")
    
    print(f"\nüéØ RECOMMANDATION STRAT√âGIQUE:")
    print(f"   1. Traiter les {len(critical_issues + high_issues)} probl√®mes prioritaires")
    print(f"   2. Timeframe global: 6-8 semaines")
    print(f"   3. Budget estim√©: ‚Ç¨50k-100k R&D + am√©lioration produit")
    print(f"   4. ROI attendu: +200-300% sur 12 mois")

def main():
    """Fonction principale d'analyse de priorit√©s business."""
    
    print("üéØ ANALYSEUR DE PRIORIT√âS BUSINESS")
    print("Bas√© sur les r√©sultats d'analyse Groq")
    print("=" * 60)
    
    # Charger r√©sultats Groq
    groq_data = load_groq_results()
    if not groq_data:
        return
    
    # Analyser priorit√©s business
    business_priorities = analyze_business_priorities(groq_data)
    
    if business_priorities:
        # G√©n√©rer r√©sum√© ex√©cutif
        topic_descriptions = groq_data['discovery_phase']['topic_descriptions']
        generate_executive_summary(business_priorities, topic_descriptions)
        
        # Sauvegarder analyse priorit√©s
        output_file = "V1.0/data/processed/business_priorities_analysis.json"
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'business_priorities': business_priorities,
                    'analysis_metadata': {
                        'total_reviews_analyzed': len(groq_data['analysis_results']),
                        'topics_discovered': len(groq_data['discovery_phase']['discovered_topics']),
                        'analysis_date': '2025-01-09',
                        'method': 'groq_llm_frequency_severity_matrix'
                    }
                }, f, indent=2, ensure_ascii=False)
            
            print(f"\nüíæ Analyse sauv√©e: {output_file}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sauvegarde: {e}")
    
    print(f"\nüéâ ANALYSE DE PRIORIT√âS TERMIN√âE!")
    print(f"üíº L'entreprise dispose maintenant d'un plan d'am√©lioration prioris√©")

if __name__ == "__main__":
    main()